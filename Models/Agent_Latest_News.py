# -*- coding: utf-8 -*-
"""web-search.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/aurelio-labs/cookbook/blob/main/gen-ai/google-ai/gemini-2/web-search.ipynb

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aurelio-labs/cookbook/blob/main/gen-ai/google-ai/gemini-2/web-search.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/aurelio-labs/cookbook/blob/main/gen-ai/google-ai/gemini-2/web-search.ipynb)

# Gemini 2.0 Flash Web Search + Citations

## Setup Instructions

This notebook has been tested both locally with Python `3.12.7` and in Google Colab with Python `3.10.12`.

To run locally, please refer to the [setup instructions with `uv` here](https://github.com/aurelio-labs/agents-course/blob/main/local-setup.md). To run in Google Colab, simply run all cells in the notebook.

## Setup with Google AI

To begin, we will need a Google API key. For that, you can setup an account in [Google AI Studio](https://aistudio.google.com). To initialize and begin using Gemini 2 that is all we need, but later we will need to upgrade our plan to get access to the Google Search tool.

After you have your account and API key, we initialize our [`google.genai` client](https://github.com/googleapis/python-genai):
"""

import os
from getpass import getpass
from google import genai

# pass your API key here
os.environ["GOOGLE_API_KEY"] = os.getenv("GOOGLE_API_KEY") or getpass(
    "Enter Google API Key: "
)
# initialize our client
client = genai.Client()

"""To generate some text with Gemini we call the `generate_content` method, Gemini does tend to respond with markdown, and is pretty verbose, so we'll use IPython's `Markdown` to display the output."""

from IPython.display import Markdown

model_id = "gemini-2.0-flash-exp"

response = client.models.generate_content(
    model=model_id, contents='What is Gemini?'
)
Markdown(response.text)

"""We got a pretty descriptive response. Now let's take a look at tool use in Gemini, starting with the `GoogleSearch` tool.

_Note: to use this tool, you **must** upgrade your plan, you can do that by navigating to your Google AI studio settings and clicking the **API Plan Information** link. For the purposes of this notebook, you should be covered by their free allowance but in any case you must have billing enabled._
"""

from google.genai.types import Tool, GoogleSearch

search_tool = Tool(google_search=GoogleSearch())

"""To use the tool, we must create a [`GenerateContentConfig` object](https://github.com/googleapis/python-genai/blob/cf3c476ea300acc09b514d23b5f1f08c05efce60/google/genai/types.py#L1404). This object is used to configure input into Gemini, this can include `system_instructions`, `temperature`, `max_output_tokens`, our `response_modalities`, and _very importantly_, our `tools`.

Most of these parameters are optional and the _defaults_ seem to depend on the model being used although it isn't clear what the default parameters are for Gemini 2.0 Flash. Nonetheless, for parameters whose defaults are more easily guessable we have included them in our `config` object definition below.
"""

from google.genai.types import GenerateContentConfig

config = GenerateContentConfig(
    system_instruction=(
        "You are a helpful assistant that provides up to date information "
        "to help the user in their research."
    ),
    tools=[search_tool],
    response_modalities=["TEXT"],
    temperature=0.0,  # likely default
    candidate_count=1,  # likely default
    # following are some other parameters, all optional
    #top_p,
    #top_k,
    #max_output_tokens,
    #max_tokens,
    #stop_sequences,
    #safety_settings,
)
config

"""Now we have our `config` setup, we can go ahead and ask Gemini about the latest news in AI, by default Gemini would not be able to answer this question, but we can get up to date information by augmenting Gemini's knowledge with the `GoogleSearch` tool."""

response = client.models.generate_content(
    model=model_id,
    contents="Tell me the latest news in AI",
    config=config
)
Markdown(response.text)

"""We can look at the `grounding_metadata` to see what sources were used to generate the response."""

response.candidates[0].grounding_metadata.__dict__

"""Each source used is collected inside a `GroundingChunk` object. Inside that we can access the `web` property which contains a `GroundingChunkWeb` containing the source website `title` and `uri`, which we can use to build a list of sources:"""

link_str = ""
for i, chunk in enumerate(response.candidates[0].grounding_metadata.grounding_chunks):
    title = chunk.web.title
    link = chunk.web.uri
    link_str += f"[{i+1}] [{title}]({link})\n\n"
Markdown(link_str)

"""That's great, but we can go a little deeper. Inside `response.candidates[0].grounding_metadata` we also have a `grounding_support` property containing a list of `GroundingSupport` objects, each of those mapping to the `GroundingChunk` objects that we already parsed above. We'll combine this information with our `title` and `link` data to create a list of `Citation` objects."""

from pydantic import BaseModel

class Citation(BaseModel):
    title: str
    score: float
    start_index: int
    end_index: int
    chunk_index: int
    link: str

    def get_link(self):
        return f"_[[{self.chunk_index+1}]({self.link})]_"

    def count_chars(self):
        return len(self.get_link())

citations = []
for support in response.candidates[0].grounding_metadata.grounding_supports:
    chunk_index = support.grounding_chunk_indices[0]
    citations.append(
        Citation(
            title=response.candidates[0].grounding_metadata.grounding_chunks[chunk_index].web.title,
            score=support.confidence_scores[0],
            start_index=support.segment.start_index,
            end_index=support.segment.end_index,
            chunk_index=chunk_index,
            link=response.candidates[0].grounding_metadata.grounding_chunks[chunk_index].web.uri,
        )
    )

# sort citations by start_index
citations.sort(key=lambda x: x.start_index)
citations

"""We can get our citation links like so:"""

citations[0].get_link()

"""With all of this information, we can go back to our original `response.text` and add these into our response."""

final_response = response.text
offset = 0
for citation in citations:
    final_response = (
        final_response[:citation.end_index+offset] +
        citation.get_link() +
        final_response[citation.end_index+offset:]
    )
    offset += citation.count_chars()
Markdown(final_response)

"""We now have functional inline citations inside our response, let's finish by adding a final block containing the more detailed citations."""

final_response = f"{final_response}\n\n**Citations**\n\n{link_str}"
Markdown(final_response)

"""---"""